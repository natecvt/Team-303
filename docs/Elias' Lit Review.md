Status: #literature 
Tags: `=this.file.tags`
Links: `=this.file.outlinks`

---
Team 303: Print Farm Automation

Source: [https://www.agvnetwork.com/types-of-navigation-systems-automated-guided-vehicles](https://www.agvnetwork.com/types-of-navigation-systems-automated-guided-vehicles)

In this article there are various ways that an automated guided vehicle (AGV) can be guided: Laser Guided, Magnetic Tape, Magnetic Spot, Inductive Wire, QR Code, and Optical navigation.

![[Pasted image 20251005054650.png]]

Above is a picture that represents how each navigation system would operate. Unfortunately the Laser Guided, Natural Feature, and Inductive Wire navigation systems won’t be able to be implemented for our project. The Laser Guided navigation system involves an invasive design by attaching multiple reflectors around the specified location along with the AGV which would go against the requirements of our sponsor as well as being extremely expensive. The Natural Feature navigation system won’t be able to be implemented due to extensive coding required to make a complete and safe mapping system, if our team enlisted an expert in that field then it would be feasible. The Inductive Wire navigation system won’t be able to be implemented due to it being an invasive process of installing within the floor of the location which the sponsor will not agree to. The Magnetic Tape navigation system is non-invasive and can be easily placed on any surface. This method is extremely accurate, ± 2 mm, will not be disturbed by dust or dirt on top of the tape and is relatively inexpensive. This works by having the AGV follow the tape pathway using a sensor that detects the magnetic force of the tape. The Magnetic Spot navigation system involves the use of following small cylindrical magnetic spots and are installed every 250-500 mm. This method works by having the AGV going from one spot to the next using hall-effect sensors, encoders, and gyro sensors to reduce the effect of steering angle errors. When compared to the Magnetic Tape system I believe that this navigation system would be inferior due to the amount of sensors required to operate in the spotted path. The QR Code navigation uses computer vision technology to “see” the QR codes placed around the location which then tells the AGV where it is in relation to everything in the location. This method is comparable to the Magnetic Tape method and I believe would also be easy to implement mechanically; however, it would put more strain on the programming team to implement.

Source:

[https://www.roboteq.com/applications/all-blogs/18-building-a-magnetic-track-guided-agv](https://www.roboteq.com/applications/all-blogs/18-building-a-magnetic-track-guided-agv)

The first source that I found gives detailed information about magnetic tracks and how they could be implemented into an AGV. The magnetic track is made out of an adhesive magnet tape that is placed on the floor. The AGV in the article uses a MGS1600 sensor to measure the distance between the center of the track and itself to then adjust the steering of the AGV to remain on the center of the track, with the addition of markers outside the main track to indicate stops and forks in the track. This could be implemented into our development of a solution by creating an AGV that would travel on a designated track to move on so it could procure the prints from the 3D printers and move to a designated location using the markers. The benefits of this would be that the magnetic track would be easy to install, easy to change, non-invasive, and be immune to dirt and other small debris. This could lower the cost compared to creating a rail system. The cost for 50 ft of track is $80 and $3.25 for the markers which would only amount to 3.33% of our total budget. Contrary to the cost of the track the sensor provided in the article costs $515 which amounts to 20.6% of the budget. However, the article gives all the necessary information on how to program the sensor including a basic set of code to modify to fit our needs. This would significantly lower the workload and time required for the programming team once the chassis design is designed/developed. The article also discusses potential chassis designs that could be implemented including: 4 Wheel Drive, Center Drive & Casters, Steerable Drive Motor, and Rear Drive & Rack Steering.

![[Pasted image 20251005054702.png]]

The 4 Wheel Drive and Center Drive designs are able to reverse which could lead to even more simplification of the track system. These chassis would be able to be a solid base to install whatever grabbing apparatus that we develop. The article also gives information on how the MGS1600 sensor would interface with the motor controllers. They would be connected through the use of wire and setting the sensor to Multi-PWM mode, where the data from the sensor is transferred in the background. Additional data can be sent and received if a problem arises as well. Overall this method would be easy for the mechanical team to implement and with the code provided by the article it would be very feasible to have a working prototype by the end of the year.

Source:

[https://www.geeksforgeeks.org/computer-vision/computer-vision](https://www.geeksforgeeks.org/computer-vision/computer-vision)

In this article a tutorial on how Computer Vision and details on how it can be implemented into a system are given. Computer Vision is a branch of Artificial Intelligence that helps computers “see” and understand that visual information. This would be very useful for implementing the QR Code navigation system into our AGV if it is chosen. Computer Vision works by capturing images with a camera and then processing those images to identify the information that corresponds to them. The system would need to be either trained in identifying those images or directly given information on them. In the case of QR codes the system would directly be given information for each QR code and its corresponding position. This could potentially lead to problems if the QR codes are not set up in the correct position. Below is a picture comparing Human Vision and Computer Vision.

![[Pasted image 20251005054734.png]]

The article provides popular libraries for Computer Vision which can be used to jump start the development of our own version. The most useful of the libraries would be _scikit-image_ and _OpenCV_ as the first library deals with algorithms pertaining to image recognition and processing and the former deals with image processing and real-time applications. Deep learning has played a major role in advancing Computer Vision by allowing computers to understand the visual data that it acquires and comes from several key learning modules. These models include Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Vision Transformers (ViT), and Vision Language Models. The modules that can be adapted to our purpose would be CNNs to be able to learn spatial information from the images collected and VAEs to be able to have the computer successfully identify the QR codes that are placed around the location. The article also discusses the tasks for Computer Vision which include Image Classification, Object Detection, and Image Segmentation. Image Classification involves analyzing the image and assigning it a specific label which would be the cornerstone for using Computer Vision to identify QR codes and label them with their corresponding position. Object Detection involves identifying and locating objects by putting boundary boxes around them. This makes identification of QR codes easier in that each are put into its own box and then identified. Image Segmentation is similar to Object Detection but it partitions the image into regions and identifies objects at a pixel level. This is essential to be able to make out every detail of the QR codes that will be used in the process. Overall the use of Computer Vision will rely heavily on how well the machine is trained which could pose an issue as it would be the first time our team will do this.
# References
